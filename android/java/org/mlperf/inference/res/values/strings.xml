<resources>
  <string name="app_name" description="Name of App [CHAR_LIMIT=50]">MLPerf Mobile</string>

  <!-- Strings of top menu -->
  <string name="action_settings" description="Action: Settings [CHAR_LIMIT=50]">Settings</string>
  <string name="action_play" description="Action: Play [CHAR_LIMIT=50]">Play</string>
  <string name="action_stop" description="Action: Stop [CHAR_LIMIT=50]">Stop</string>
  <string name="action_refresh" description="Action: Refresh [CHAR_LIMIT=50]">Refresh</string>

  <!-- Values for delegate setting -->
  <string name="delegate_none" description="CPU [CHAR_LIMIT=50]">None</string>
  <string name="delegate_gpu" description="GPU [CHAR_LIMIT=50]">GPU (F32)</string>
  <string name="delegate_gpu_f16" description="GPU F16 [CHAR_LIMIT=50]">GPU (F16)</string>
  <string name="delegate_nnapi" description="NNAPI [CHAR_LIMIT=50]">NNAPI</string>
  <string name="versionLabel">Version %1$s</string>
  <string name="privacyPrompt">Would you like to share your anonymous results and basic system
information with MLCommons.org to help accelerate innovation?</string>
  <string name="allow">Share</string>
  <string name="privacy_policy_btn">privacy policy.</string>
  <string name="dontAllow">Don\’t Share</string>
  <string name="promptSubText">By clicking share you agree to our</string>
  <string name="calculatingActivityLabel"><![CDATA[Measure]]></string>
  <string name="measureCapabilityText">Measure your device’s performance for:</string>
  <string name="cancel">Cancel</string>

  <!--getString(R.string.progressMessage, number.toString())-->
  <string name="progressMessage">%1$s</string>
  <string name="downloadedPercent">%1$s%%</string>
  <string name="dontCloseApp">Don\'t close the app!</string>
  <string name="performance">Performance</string>
  <string name="accuracy">Accuracy</string>
  <string name="detailed_results">Detailed Results</string>
  <string name="testAgain">Test Again</string>
  <string name="tryAgain">Try again</string>
  <string name="shareResults">Share results</string>
  <string name="sendTo">Share results</string>
  <string name="placeholder">Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sagittis bibendum rutrum nisi tincidunt facilisi diam amet adipiscing. Est eu auctor eu, sit aliquam ut felis. Ut ultrices in porttitor feugiat enim. Aenean sed quam varius duis dictumst nec nunc</string>
  <string name="settings">Settings</string>
  <string name="privacy_policy">Privacy Policy</string>
  <string name="eula">End User License Agreement</string>
  <string name="go">GO</string>
  <string name="wait">&#8987;</string>
  <string name="sharing">Sharing</string>
  <string name="uhoh">Uh-Oh!</string>
  <string name="genericError">Something went wrong.</string>
  <string name="configError">Please try selecting different configurations and run the test again.</string>
  <string name="ramSizeError">Not enough RAM size: %1$dGb required, but only %2$dGb presented.</string>
  <string name="modify_config">Modify Configuration</string>
  <string name="report_bug">Report Bug</string>
  <string name="title_activity_settings">SettingsActivity</string>
  <string name="title_backend">Backend: %1$s</string>
  <string name="title_runtime">Runtime: %1$s</string>
  <string name="title_accelerator">Accelerator: %1$s</string>

  <!-- Preference Titles -->
  <string name="messages_header">Customize</string>
  <string name="configurationSummary">Please select a system configuration to measure for each benchmark.</string>
  <string name="view_developer_tool">View Developer Tool</string>
  <string name="language_processing">Language Processing</string>
  <string name="image_segmentation">Image Segmentation</string>
  <string name="object_detection">Object Detection</string>
  <string name="image_classification">Image Classification</string>
  <string name="image_classification_offline">Image Classification (offline)</string>
  <string name="customize_config_title">Configuration</string>
  <string name="run">Run</string>
  <string name="privacyPolicyUrl">https://mlcommons.org/mobile_privacy</string>
  <string name="eulaUrl">https://mlcommons.org/mobile_eula</string>
  <string name="reportBugUrl">https://mlcommons.org/mobile-issue/</string>
  <string name="developer_tool">Developer Tool</string>
  <string name="error_unsupported">It looks like your device is not supported.</string>
  <string name="error_try_another_device">Please try the app on another device.</string>
  <string name="error_try_restart_application">Please try to restart application.</string>
  <string name="quit">Quit</string>
  <string name="show_log">show_log</string>
  <string name="developer_lorem_ipsum">Lorem ipsum dolor sit amet, consectetur adipiscing elit. Ultricies in vel orci, auctor enim arcu dui duis.
    \n---------------------------\n Enim, eget egestas dictum ac. Donec et volutpat tortor, amet. Nunc viverra sed egestas euismod risus, blandit.
    \n---------------------------\n
    Lorem ipsum dolor sit amet, consectetur adipiscing elit. Ultricies in vel orci, auctor enim arcu dui duis. Enim, eget egestas dictum ac. \n---------------------------\nDonec et volutpat tortor, amet. Nunc viverra sed egestas euismod risus, blandit. Lorem ipsum dolor sit amet, consectetur adipiscing elit.
    Lorem ipsum dolor sit amet, consectetur adipiscing elit. Ultricies in vel orci, auctor enim arcu dui duis.
    \n---------------------------\n Enim, eget egestas dictum ac. Donec et volutpat tortor, amet. Nunc viverra sed egestas euismod risus, blandit.
    \n---------------------------\n
    Lorem ipsum dolor sit amet, consectetur adipiscing elit. Ultricies in vel orci, auctor enim arcu dui duis. Enim, eget egestas dictum ac. \n---------------------------\nDonec et volutpat tortor, amet. Nunc viverra sed egestas euismod risus, blandit. Lorem ipsum dolor sit amet, consectetur adipiscing elit. </string>
  <string name="measuring">Measuring...</string>
  <string name="share_subtitle">Share your anonymous results\nand basic system information.</string>
  <string name="model_not_ready">GO</string>
  <string name="resultsTitlePerformance">Results (qps)</string>
  <string name="resultsTitleAccuracy">Results</string>
  <string name="calculating">Measuring...</string>
  <string name="detailed_results_text">Detailed Results</string>
  <string name="loading_content">Loading content...</string>
  <string name="storage_permission">Storage Permission</string>
  <string name="storage_justification">Allow the MLPerf app to download and store the test datasets that are required to run the benchmarks.</string>
  <string name="allow_permission">Allow</string>
  <string name="exit_app">Exit App</string>
  <string name="allow_in_settings">Allow in Settings</string>
  <string name="cooldown_subtitle">Pause %1$d minutes before running each\nbenchmark to avoid thermal throttling.</string>
  <string name="cooldown">Cooldown</string>
  <string name="waiting_for_benchmark_finish">Wait for benchmark to finish</string>
  <string name="submission_mode">Submission mode</string>
  <string name="submission_mode_subtitle">Switch on/off submission mode</string>

  <!-- Snackbar titles-->
  <string name="snack_title_IC">Image Classification</string>
  <string name="snack_title_IS">Image Segmentation</string>
  <string name="snack_title_OD">Object Detection</string>
  <string name="snack_title_LU">Language Processing</string>
  <string name="snack_title_details_IC">Image classification picks the best label to describe an input image and is commonly used for photo search and text extraction. The MobileNetEdgeTPU reference model is evaluated on the ImageNet 2012 validation dataset and requires 74.66% (98% of FP32 accuracy) Top-1 accuracy (app uses a different dataset).\n\nThe MobileNetEdgeTPU network is a descendent of the MobileNet-v2 family that is optimized for low-latency and mobile accelerators. The MobileNetEdgeTPU model architecture is based on convolutional layers with inverted residuals and linear bottlenecks, similar to MobileNet v2, but is optimized by introducing fused inverted bottleneck convolutions to improve hardware utilization, and removing hard-swish and squeeze-and-excite blocks.</string>
  <string name="snack_title_details_IS">Semantic image segmentation partitions an input image into labeled objects at pixel granularity, and is used for complex image manipulation such as red-eye reduction as well as automotive and medical applications. The reference model is theDeepLabv3+ network with a MobileNet-v2 feature extractor, using a 512x512 input image resolution. Performance and accuracy are evaluated on the ADE20K validation dataset. The benchmark requires a mean Intersection Over Union (mIoU) value of 53.156% (97% of FP32 accuracy).\n\nDeepLabV3+ uses an encoder-decoder architecture with atrous spatial pyramid pooling and a modular feature extractor. We selected MobileNet-V2 as the feature extractor, which enables state-of-the-art model accuracy within a constrained computational budget.</string>
  <string name="snack_title_details_OD">Object detection draws bounding boxes around recognized objects in an input image, assigning each one a label. This is a common approach for identifying objects in photos, and automotive safety. The reference model is a Single Shot Detector based MobileDet model operating on the COCO 2017 validation dataset with a mean Average Precision (mAP) of 27.1 (95% of FP32 accuracy).\n\nMobileDet-SSD provides substantial improvements in the latency-accuracy trade-off by incorporating regular convolutions along with depthwise-separable convolutions in the search space for the object detection task, and effectively placing them in the network via neural architecture search (from: https://arxiv.org/pdf/2004.14525.pdf)</string>
  <string name="snack_title_details_LU">Question Answering finds the  best answer to an input question based on a body of text. The reference model, MobileBERT, is evaluated on the Stanford Question Answering Dataset (SQUAD) v1.1 Dev and achieves an F1-score of 90.0.\n\nMobileBERT is a thin, mobile-optimized version of the larger BERT (BERT_LARGE) network, equipped with bottleneck structures and a carefully designed balance between self-attensions and feed-forward networks. Like BERT, it is task-agnostic, applicable for a variety of downstream NLP tasks, but for MLPerf we use the variant fine-tuned for Q&amp;A.</string>
</resources>
